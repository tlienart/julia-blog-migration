<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/julia-blog-migration/libs/katex/katex.min.css"> <link rel=stylesheet  href="/julia-blog-migration/libs/highlight/github.min.css"> <link rel=stylesheet  href="/julia-blog-migration/css/judoc.css"> <title>Distributed Numerical Optimization</title> <div class=jd-content > <h1><a id=distributed_numerical_optimization  href="#distributed_numerical_optimization">Distributed Numerical Optimization</a></h1> This post walks through the parallel computing functionality of Julia to implement an asynchronous parallel version of the classical <em>cutting-plane</em> algorithm for convex &#40;nonsmooth&#41; optimization, demonstrating the complete workflow including running on both Amazon EC2 and a large multicore server. I will quickly review the cutting-plane algorithm and will be focusing primarily on parallel computation patterns, so don&#39;t worry if you&#39;re not familiar with the optimization side of things.</p> <h3><a id=cutting-plane_algorithm  href="#cutting-plane_algorithm">Cutting-plane algorithm</a></h3> The cutting-plane algorithm is a method for solving the optimization problem</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math><semantics><mrow><munder><mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>x</mi><mo>∈</mo><msup><mi mathvariant=double-struck >R</mi><mi>d</mi></msup></mrow></munder><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>f</mi><mi>i</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">\min_{x \in \mathbb R^d} \sum_{i=1}^n f_i(x)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.66786em;"><span style="top:-1.98658em;margin-left:0em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathbb mtight">R</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7820285714285713em;"><span style="top:-2.786em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">d</span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.7em;"><span class=pstrut  style="height:2.7em;"></span><span><span class=mop >min</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.8407899999999999em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class=pstrut  style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class=pstrut  style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:1.277669em;"><span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathdefault">x</span><span class=mclose >)</span></span></span></span></span> <p>where the functions <span class=katex ><span class=katex-mathml ><math><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex"> f_i </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are convex but not necessarily differentiable. The absolute value function <span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi mathvariant=normal >∣</mi><mi>x</mi><mi mathvariant=normal >∣</mi></mrow><annotation encoding="application/x-tex"> |x| </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord >∣</span><span class="mord mathdefault">x</span><span class=mord >∣</span></span></span></span> and the 1-norm <span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi mathvariant=normal >∣</mi><mi mathvariant=normal >∣</mi><mi>x</mi><mi mathvariant=normal >∣</mi><msub><mi mathvariant=normal >∣</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex"> ||x|| _ 1 </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord >∣</span><span class=mord >∣</span><span class="mord mathdefault">x</span><span class=mord >∣</span><span class=mord ><span class=mord >∣</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> are typical examples. Important applications also arise from <a href="http://en.wikipedia.org/wiki/Lagrangian_relaxation">Lagrangian relaxation</a>. The idea of the algorithm is to approximate the functions <span class=katex ><span class=katex-mathml ><math><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex"> f_i </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> with piecewise linear models <span class=katex ><span class=katex-mathml ><math><semantics><mrow><msub><mi>m</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex"> m_i </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.58056em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathdefault">m</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> which are built up from information obtained by evaluating <span class=katex ><span class=katex-mathml ><math><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex"> f_i </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> at different points. We iteratively minimize over the models to generate candidate solution points.</p> <p>We can state the algorithm as</p> <ol> <li><p>Choose starting point <span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex"> x </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> .</p> <li><p>For <span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi>i</mi><mo>=</mo><mn>1</mn><mo separator=true >,</mo><mo>…</mo><mo separator=true >,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">i = 1,\dots,n</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class=mord >1</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=minner >…</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">n</span></span></span></span> , evaluate <span class=katex ><span class=katex-mathml ><math><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> f_i(x) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathdefault">x</span><span class=mclose >)</span></span></span></span> and update corresponding model <span class=katex ><span class=katex-mathml ><math><semantics><mrow><msub><mi>m</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex"> m_i </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.58056em;vertical-align:-0.15em;"></span><span class=mord ><span class="mord mathdefault">m</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> .</p> <li><p>Let the next</p> </ol> <p>candidate <span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex"> x </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> be the minimizer of <span class=katex ><span class=katex-mathml ><math><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>m</mi><mi>i</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> \sum_{i=1}^n m_i(x) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.104002em;vertical-align:-0.29971000000000003em;"></span><span class=mop ><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.804292em;"><span style="top:-2.40029em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.29971000000000003em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathdefault">m</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathdefault">x</span><span class=mclose >)</span></span></span></span> .</p> <ol start=4 > <li><p>If not converged, goto step 2.</p> </ol> <p>If it is costly to evaluate <span class=katex ><span class=katex-mathml ><math><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> f_i(x) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathdefault">x</span><span class=mclose >)</span></span></span></span> , then the algorithm is naturally parallelizable at step 2. The minimization in step 3 can be computed by solving a linear optimization problem, which is usually very fast. &#40;Let me point out here that Julia has interfaces to linear programming and other optimization solvers under <a href="http://juliaopt.org/">JuliaOpt</a>.&#41;</p> <p>Abstracting the math, we can write the algorithm using the following Julia code. <pre><code class="julia hljs"><span class=hljs-comment ># functions initialize, isconverged, solvesubproblem, and process implemented elsewhere</span>
state, subproblems = initialize()
<span class=hljs-keyword >while</span> !isconverged(state)
    results = map(solvesubproblem,subproblems)
    state, subproblems = process(state, results)
<span class=hljs-keyword >end</span></code></pre> The function <code>solvesubproblem</code> corresponds to evaluating <span class=katex ><span class=katex-mathml ><math><semantics><mrow><msub><mi>f</mi><mi>i</mi></msub><mo stretchy=false >(</mo><mi>x</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> f_i(x) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mord ><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class="mord mathdefault">x</span><span class=mclose >)</span></span></span></span> for a given <span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex"> i </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex"> x </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> &#40;the elements of <code>subproblems</code> could be tuples <code>&#40;i,x&#41;</code>&#41;. The function <code>process</code> corresponds to minimizing the model in step 3, and it produces a new state and a new set of subproblems to solve.</p> <p>Note that the algorithm looks much like a map-reduce that would be easy to parallelize using many existing frameworks. Indeed, in Julia we can simply replace <code>map</code> with <code>pmap</code> &#40;parallel map&#41;. Let&#39;s consider a twist that makes the parallelism not so straightforward.</p> <h3><a id=asynchronous_variant  href="#asynchronous_variant">Asynchronous variant</a></h3> Variability in the time taken by the <code>solvesubproblem</code> function can lead to load imbalance and limit parallel efficiency as workers sit idle waiting for new tasks. Such variability arises naturally if <code>solvesubproblem</code> itself requires solving a optimization problem, or if the workers and network are shared, as is often the case with cloud computing.</p> <p>We can consider a new variant of the cutting-plane algorithm to address this issue. The key point is</p> <ul> <li><p>When proportion <span class=katex ><span class=katex-mathml ><math><semantics><mrow><mn>0</mn><mo>&lt;</mo><mi>α</mi><mo>≤</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 &lt; \alpha \le 1 </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.68354em;vertical-align:-0.0391em;"></span><span class=mord >0</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >&lt;</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.7719400000000001em;vertical-align:-0.13597em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >≤</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >1</span></span></span></span> of subproblems for a given candidate have been solved, generate a new candidate and corresponding set of subproblems by using whatever information is presently available.</p> </ul> <p>In other words, we generate new tasks to feed to workers without needing to wait for all current tasks to complete, making the algorithm asynchronous. The algorithm remains convergent, although the total number of iterations may increase. For more details, see this <a href="http://dx.doi.org/10.1023/A:1021858008222">paper</a> by Jeff Linderoth and Stephen Wright.</p> <p>By introducing asynchronicity we can no longer use a nice black-box <code>pmap</code> function and have to dig deeper into the parallel implementation. Fortunately, this is easy to do in Julia.</p> <h3><a id=parallel_implementation_in_julia  href="#parallel_implementation_in_julia">Parallel implementation in Julia</a></h3> <p>Julia implements distributed-memory parallelism based on one-sided message passing, where process push work onto others &#40;via <code>remotecall</code>&#41; and the results are retrieved &#40;via <code>fetch</code>&#41; by the process which requires them. Macros such as <code>@spawn</code> and <code>@parallel</code> provide pretty syntax around this low-level functionality. This model of parallelism is very different from the typical SIMD style of MPI. Both approaches are useful in different contexts, and I expect an MPI wrapper for Julia will appear in the future &#40;see also <a href="https://github.com/lcw/julia-mpi">here</a>&#41;.</p> <p>Reading the <a href="http://docs.julialang.org/en/release-0.1/manual/parallel-computing/">manual</a> on parallel computing is highly recommended, and I won&#39;t try to reproduce it in this post. Instead, we&#39;ll dig into and extend one of the examples it presents.</p> <p>The implementation of <code>pmap</code> in Julia is <pre><code class="julia hljs"><span class=hljs-keyword >function</span> pmap(f, lst)
    np = nprocs()  <span class=hljs-comment ># determine the number of processors available</span>
    n = length(lst)
    results = cell(n)
    i = <span class=hljs-number >1</span>
    <span class=hljs-comment ># function to produce the next work item from the queue.</span>
    <span class=hljs-comment ># in this case it's just an index.</span>
    next_idx() = (idx=i; i+=<span class=hljs-number >1</span>; idx)
    <span class=hljs-meta >@sync</span> <span class=hljs-keyword >begin</span>
        <span class=hljs-keyword >for</span> p=<span class=hljs-number >1</span>:np
            <span class=hljs-keyword >if</span> p != myid() || np == <span class=hljs-number >1</span>
                <span class=hljs-meta >@spawnlocal</span> <span class=hljs-keyword >begin</span>
                    <span class=hljs-keyword >while</span> <span class=hljs-literal >true</span>
                        idx = next_idx()
                        <span class=hljs-keyword >if</span> idx &gt; n
                            <span class=hljs-keyword >break</span>
                        <span class=hljs-keyword >end</span>
                        results[idx] = remotecall_fetch(p, f, lst[idx])
                    <span class=hljs-keyword >end</span>
                <span class=hljs-keyword >end</span>
            <span class=hljs-keyword >end</span>
        <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >end</span>
    results
<span class=hljs-keyword >end</span></code></pre> On first sight, this code is not particularly intuitive. The <code>@spawnlocal</code> macro creates a <a href="http://docs.julialang.org/en/latest/manual/control-flow/#man-tasks"><i>task</i></a> on the <em>master process</em> &#40;e.g. process 1&#41;. Each task feeds work to a corresponding worker; the call <code>remotecall_fetch&#40;p, f, lst&#91;idx&#93;&#41;</code> function calls <code>f</code> on process <code>p</code> and returns the result when finished. Tasks are uninterruptable and only surrender control at specific points such as <code>remotecall_fetch</code>. Tasks cannot directly modify variables from the enclosing scope, but the same effect can be achieved by using the <code>next_idx</code> function to access and mutate <code>i</code>. <em>The task idiom functions in place of using a loop to poll for results from each worker process.</em></p> <p>Implementing our asynchronous algorithm is not much more than a modification of the above code: <pre><code class="julia hljs"><span class=hljs-comment ># given constants n and 0 &lt; alpha &lt;= 1</span>
<span class=hljs-comment ># functions initialize and solvesubproblem defined elsewhere</span>
np = nprocs()
state, subproblems = initialize()
converged = <span class=hljs-literal >false</span>
isconverged() = converged
<span class=hljs-keyword >function</span> updatemodel(mysubproblem, result)
    <span class=hljs-comment ># store result</span>
    ...
    <span class=hljs-comment ># decide whether to generate new subproblems</span>
    state.numback[mysubproblem.parent] += <span class=hljs-number >1</span>
    <span class=hljs-keyword >if</span> state.numback[mysubproblem.parent] &gt;= alpha*n &amp;&amp; !state.didtrigger[mysubproblem.parent]
        state.didtrigger[mysubproblem.parent] = <span class=hljs-literal >true</span>
        <span class=hljs-comment ># generate newsubproblems by solving linear optimization problem</span>
        ...
        <span class=hljs-keyword >if</span> ... <span class=hljs-comment ># convergence test</span>
            converged = <span class=hljs-literal >true</span>
        <span class=hljs-keyword >else</span>
            append!(subproblems, newsubproblems)
            push!(state.didtrigger, <span class=hljs-literal >false</span>)
            push!(state.numback, <span class=hljs-number >0</span>)
            <span class=hljs-comment ># ensure that for s in newsubproblems, s.parent == length(state.numback)</span>
        <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >end</span>
<span class=hljs-keyword >end</span>

<span class=hljs-meta >@sync</span> <span class=hljs-keyword >begin</span>
    <span class=hljs-keyword >for</span> p=<span class=hljs-number >1</span>:np
        <span class=hljs-keyword >if</span> p != myid() || np == <span class=hljs-number >1</span>
            <span class=hljs-meta >@spawnlocal</span> <span class=hljs-keyword >begin</span>
                <span class=hljs-keyword >while</span> !isconverged()
                    <span class=hljs-keyword >if</span> length(subproblems) == <span class=hljs-number >0</span>
                        <span class=hljs-comment ># no more subproblems but haven't converged yet</span>
                        yield()
                        <span class=hljs-keyword >continue</span>
                    <span class=hljs-keyword >end</span>
                    mysubproblem = shift!(subproblems) <span class=hljs-comment ># pop subproblem from queue</span>
                    result = remotecall_fetch(p, solvesubproblem, mysubproblem)
                    updatemodel(mysubproblem, result)
                <span class=hljs-keyword >end</span>
            <span class=hljs-keyword >end</span>
        <span class=hljs-keyword >end</span>
    <span class=hljs-keyword >end</span>
<span class=hljs-keyword >end</span></code></pre> where <code>state</code> is an instance of a type defined as <pre><code class="julia hljs"><span class=hljs-keyword >type</span> State
    didtrigger::<span class=hljs-built_in >Vector</span>{<span class=hljs-built_in >Bool</span>}
    numback::<span class=hljs-built_in >Vector</span>{<span class=hljs-built_in >Int</span>}
    ...
<span class=hljs-keyword >end</span></code></pre> There is little difference in the structure of the code inside the <code>@sync</code> blocks, and the asynchronous logic is encapsulated in the local <code>updatemodel</code> function which conditionally generates new subproblems. A strength of Julia is that functions like <code>pmap</code> are implemented in Julia itself, so that it is particularly straightforward to make modifications like this.</p> <h3><a id=running_it  href="#running_it">Running it</a></h3> Now for the fun part. The complete cutting-plane algorithm &#40;along with additional variants&#41; is implemented in <a href="https://github.com/mlubin/JuliaBenders">JuliaBenders</a>. The code is specialized for <a href="http://en.wikipedia.org/wiki/Stochastic_programming">stochastic programming</a> where the cutting-plane algorithm is known as the <a href="http://www.springerreference.com/docs/html/chapterdbid/72429.html">L-shaped method</a> or Benders decomposition and is used to decompose the solution of large linear optimization problems. Here, <code>solvesubproblem</code> entails solving a relatively small linear optimization problem. Test instances are taken from the previously mentioned <a href="http://dx.doi.org/10.1023/A:1021858008222">paper</a>.</p> <p>We&#39;ll first run on a large multicore server. The <code>runals.jl</code> &#40;asynchronous L-shaped&#41; file contains the algorithm we&#39;ll use. Its usage is <pre><code class="julia hljs">julia runals.jl [data source] [num subproblems] [async param] [block size]</code></pre>
 where <code>&#91;num subproblems&#93;</code> is the 
<span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span>
 as above and <code>&#91;async param&#93;</code> is the proportion 
<span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span></span></span></span>
. By setting 
<span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi>α</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\alpha = 1</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >1</span></span></span></span>
 we obtain the synchronous algorithm. For the asynchronous version we will take 
<span class=katex ><span class=katex-mathml ><math><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.6</mn></mrow><annotation encoding="application/x-tex">\alpha =
0.6</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.64444em;vertical-align:0em;"></span><span class=mord >0</span><span class=mord >.</span><span class=mord >6</span></span></span></span>
. The <code>&#91;block size&#93;</code> parameter controls how many subproblems are sent to a worker at once &#40;in the previous code, this value was always 1&#41;. We will use 4000 subproblems in our experiments.</p>
<p>To run multiple Julia processes on a shared-memory machine, we pass the <code>-p N</code> option to the <code>julia</code> executable, which will start up <code>N</code> system processes. To execute the asynchronous version with 10 workers, we run 
<pre><code class="julia hljs">julia -p <span class=hljs-number >12</span> runals.jl Data/storm <span class=hljs-number >4000</span> <span class=hljs-number >0.6</span> <span class=hljs-number >30</span></code></pre>
 Note that we start 12 processes. These are the 10 workers, the master &#40;which distributes tasks&#41;, and another process to perform the master&#39;s computations &#40;an additional refinement which was not described above&#41;. Results from various runs are presented in the table below.</p>

<table style="text-align:right;margin-left:auto;margin-right:auto" cellspacing=5 >
<tr style="text-align:center">
	<td> 
	<td colspan=2  style="border-bottom-style:solid;border-bottom-width:2px">Synchronous
	<td colspan=2  style="border-bottom-style:solid;border-bottom-width:2px">Asynchronous

<tr style="text-align:center">
	<td style="border-bottom-style:solid;border-bottom-width:2px">No. Workers
	<td style="border-bottom-style:solid;border-bottom-width:2px">Speed
	<td style="border-bottom-style:solid;border-bottom-width:2px">Efficiency
	<td style="border-bottom-style:solid;border-bottom-width:2px">Speed
	<td style="border-bottom-style:solid;border-bottom-width:2px">Efficiency

<tr>
	<td style="text-align:center">10
	<td>154
	<td>Baseline
	<td>166
	<td>Baseline

<tr>
	<td style="text-align:center">20
	<td>309
	<td>100.3%
	<td>348
	<td>105%

<tr>
	<td style="text-align:center">40
	<td>517
	<td>84%
	<td>654
	<td>98%

<tr>
	<td style="text-align:center">60
	<td>674
	<td>73%
	<td>918
	<td>92%

</table>

<p class=caption  style="text-align:center"><b>Table:</b>
Results on a shared-memory 8x Xeon E7-8850 server. Workers correspond to
individual cores. Speed is the rate of subproblems solved per second. Efficiency
is calculated as the percent of ideal parallel speedup obtained. The superlinear
scaling observed with 20 workers is likely a system artifact.
</p>

<p>There are a few more hoops to jump through in order to run on EC2. First we must build a system image &#40;AMI&#41; with Julia installed. Julia connects to workers over ssh, so I found it useful to put my EC2 ssh key on the AMI and also set <code>StrictHostKeyChecking no</code> in <code>/etc/ssh/ssh_config</code> to disable the authenticity prompt when connecting to new workers. Someone will likely correct me on if this is the right approach.</p>
<p>Assuming we have an AMI in place, we can fire up the instances. I used an m3.xlarge instance for the master and m1.medium instances for the workers. &#40;Note: you can save a lot of money by using the spot market.&#41;</p>
<p>To add remote workers on startup, Julia accepts a file with a list of host names through the <code>--machinefile</code> option. We can generate this easily enough by using the EC2 API Tools &#40;Ubuntu package <code>ec2-api-tools</code>&#41; with the command 
<pre><code class="julia hljs">ec2-describe-instances | grep running | awk '{ print $<span class=hljs-number >5</span>; }' &gt; mfile</code></pre>
 On the master instance we can then run 
<pre><code class="julia hljs">julia --machinefile mfile runatr.jl Data/storm <span class=hljs-number >4000</span> <span class=hljs-number >0.6</span> <span class=hljs-number >30</span></code></pre>
 Results from various runs are presented in the table below.</p>

<table style="text-align:right;margin-left:auto;margin-right:auto" cellspacing=5 >
<tr style="text-align:center">
	<td> 
	<td colspan=2  style="border-bottom-style:solid;border-bottom-width:2px">Synchronous
	<td colspan=2  style="border-bottom-style:solid;border-bottom-width:2px">Asynchronous

<tr style="text-align:center">
	<td style="border-bottom-style:solid;border-bottom-width:2px">No. Workers
	<td style="border-bottom-style:solid;border-bottom-width:2px">Speed
	<td style="border-bottom-style:solid;border-bottom-width:2px">Efficiency
	<td style="border-bottom-style:solid;border-bottom-width:2px">Speed
	<td style="border-bottom-style:solid;border-bottom-width:2px">Efficiency

<tr>
	<td style="text-align:center">10
	<td>149
	<td>Baseline
	<td>151
	<td>Baseline

<tr>
	<td style="text-align:center">20
	<td>289
	<td>97%
	<td>301
	<td>99.7%

<tr>
	<td style="text-align:center">40
	<td>532
	<td>89%
	<td>602
	<td>99.5%

</table>

<p class=caption  style="text-align:center"><b>Table:</b>
Results on Amazon EC2. Workers correspond to individual m1.medium instances. The
master process is run on an m3.xlarge instance.
</p>

<p>On both architectures the asynchronous version solves subproblems at a higher rate and has significantly better parallel efficiency. Scaling is better on EC2 than on the shared-memory server likely because the subproblem calculation is memory bound, and so performance is better on the distributed-memory architecture. Anyway, with Julia we can easily experiment on both.</p>
<h3><a id=further_reading  href="#further_reading">Further reading</a></h3> A more detailed <a
href="https://github.com/JuliaLang/julia-tutorial/blob/master/NumericalOptimization/tutorial.pdf?raw=true">tutorial</a> was prepared for the Julia <a href="https://github.com/JuliaLang/julia-tutorial">IAP session</a> at MIT in January 2013.</p>

<a rel=license  href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="padding-left:0;width:100px;" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Distributed Numerical Optimization</span> by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Miles Lubin</span> is licensed under a <a rel=license  href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.

<div class=page-foot >
  <div class=copyright >
    &copy; <a href="http://www.mit.edu/~mlubin/">Miles Lubin</a>. Last modified: September 10, 2019. Website built with <a href="https://github.com/tlienart/JuDoc.jl">JuDoc.jl</a>.
  </div>
</div>

</div>